{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P4 Reproduction Script\n",
    "\"\"\"\n",
    "Title: \"Predicting At-Risk Students Using Clickstream Data in the Virtual Learning Environment\"\n",
    "Authors: Naif Radi Aljohani, Ayman Fayoumi, Saeed-Ul Hassan\n",
    "Source: Sustainability, 2019\n",
    "\n",
    "Purpose:\n",
    "This script reproduces the methodology and results of the above paper using the\n",
    "Open University Learning Analytics Dataset (OULAD). It executes the complete pipeline described in the paper:\n",
    "    - Data loading and preprocessing from studentInfo, studentVle, vle, and courses tables\n",
    "    - Filtering out Withdrawn students and merging Distinction into Pass\n",
    "    - Week-by-week aggregation of 20 VLE activity types into fixed-length (38-week) sequences\n",
    "    - Padding sequences and applying masking for LSTM input\n",
    "    - Training a deep LSTM model with three stacked layers (100–200–300 units) at multiple cut-offs:\n",
    "        * Week 5\n",
    "        * Week 10\n",
    "        * Week 20\n",
    "        * Week 38\n",
    "    - Saving trained models, predictions, and training histories\n",
    "    - Evaluating models using accuracy, precision, and recall\n",
    "    - Running baseline models (Logistic Regression, SVM, ANN) on aggregated features for comparison\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cee7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Setup\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35459c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 + 3 Data Manipulation + Feature Engineering\n",
    "si = pd.read_csv(\"studentInfo.csv\")\n",
    "sv = pd.read_csv(\"studentVle.csv\")\n",
    "vle = pd.read_csv(\"vle.csv\")\n",
    "courses = pd.read_csv(\"courses.csv\")\n",
    "print(\"Loaded studentInfo.csv:\", si.shape)\n",
    "print(\"Loaded studentVle.csv:\", sv.shape)\n",
    "print(\"Loaded vle.csv:\", vle.shape)\n",
    "\n",
    "si = si[si.final_result != \"Withdrawn\"].copy()\n",
    "si[\"final_result\"] = si[\"final_result\"].replace({\"Distinction\": \"Pass\"})\n",
    "si[\"student_course_id\"] = (\n",
    "    si[\"id_student\"].astype(str) + \"_\" +\n",
    "    si[\"code_module\"] + \"_\" + si[\"code_presentation\"]\n",
    ")\n",
    "print(\"Cleaned studentInfo:\", si.shape)\n",
    "\n",
    "sv = (\n",
    "    sv\n",
    "    .merge(vle[[\"id_site\", \"activity_type\"]], on=\"id_site\", how=\"left\")\n",
    "    .merge(\n",
    "        si[[\"id_student\", \"code_module\", \"code_presentation\", \"final_result\"]],\n",
    "        on=[\"id_student\", \"code_module\", \"code_presentation\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "sv[\"week\"] = (sv[\"date\"] // 7) + 1\n",
    "\n",
    "weekly = (\n",
    "    sv.groupby(\n",
    "        [\"id_student\", \"code_module\", \"code_presentation\", \"week\", \"activity_type\"],\n",
    "        as_index=False\n",
    "    ).agg({\"sum_click\": \"sum\"})\n",
    ")\n",
    "\n",
    "pivot = weekly.pivot_table(\n",
    "    index=[\"id_student\", \"code_module\", \"code_presentation\", \"week\"],\n",
    "    columns=\"activity_type\",\n",
    "    values=\"sum_click\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "expected_activities = [\n",
    "    'dataplus', 'dualpane', 'externalquiz', 'folder', 'forumng', 'glossary',\n",
    "    'homepage', 'htmlactivity', 'oucollaborate', 'oucontent', 'ouelluminate',\n",
    "    'ouwiki', 'page', 'questionnaire', 'quiz', 'repeatactivity', 'resource',\n",
    "    'sharedsubpage', 'subpage', 'url'\n",
    "]\n",
    "\n",
    "for act in expected_activities:\n",
    "    if act not in pivot.columns:\n",
    "        pivot[act] = 0\n",
    "\n",
    "pivot = pivot[[\"id_student\", \"code_module\", \"code_presentation\", \"week\"] + expected_activities]\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for (stu, mod, pres), group in pivot.groupby([\"id_student\", \"code_module\", \"code_presentation\"]):\n",
    "    group = group.set_index(\"week\").reindex(range(1, 39), fill_value=0)\n",
    "    X_list.append(group[expected_activities].values)\n",
    "    label = si.query(\n",
    "        \"id_student == @stu and code_module == @mod and code_presentation == @pres\"\n",
    "    )[\"final_result\"].iat[0]\n",
    "    y_list.append(1 if label == \"Pass\" else 0)\n",
    "\n",
    "X = np.stack(X_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(\"Final shape of X:\", X.shape)\n",
    "print(\"Final shape of y:\", y.shape)\n",
    "print(si[\"id_student\"].nunique())\n",
    "print(si.shape)\n",
    "print(sv[\"id_student\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 LSTM Model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"predictions\", exist_ok=True)\n",
    "os.makedirs(\"history_logs\", exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for week in [5, 10, 20, 38]:\n",
    "    model_path = f\"models/lstm_week{week}.h5\"\n",
    "    y_pred_path = f\"predictions/y_pred_week{week}.npy\"\n",
    "    y_true_path = f\"predictions/y_true_week{week}.npy\"\n",
    "    history_path = f\"history_logs/history_week{week}.npy\"\n",
    "\n",
    "    print(f\"\\n=== Week {week} ===\")\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Model for week {week} already exists. Skipping training.\")\n",
    "        model = load_model(model_path)\n",
    "        y_pred = np.load(y_pred_path)\n",
    "        y_test = np.load(y_true_path)\n",
    "    else:\n",
    "        print(f\"Training model for week {week}...\")\n",
    "        X_week = X[:, :week, :]\n",
    "        X_padded = np.zeros((X.shape[0], 38, X.shape[2]))\n",
    "        X_padded[:, :week, :] = X_week\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_padded, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Masking(mask_value=0.0, input_shape=(38, 20)))\n",
    "        model.add(LSTM(100, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(200, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(300))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        optimizer = Adam(lr=0.0001)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=60,\n",
    "            batch_size=32,\n",
    "            validation_split=0.1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        model.save(model_path)\n",
    "        np.save(history_path, history.history)\n",
    "\n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "        y_pred_labels = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "        np.save(y_pred_path, y_pred_labels)\n",
    "        np.save(y_true_path, y_test)\n",
    "\n",
    "    y_pred_labels = (y_pred >= 0.5).astype(int)\n",
    "    report = classification_report(y_test, y_pred_labels, output_dict=True, zero_division=0)\n",
    "    results.append({\n",
    "        'week': week,\n",
    "        'accuracy': round(report['accuracy'], 4),\n",
    "        'precision': round(report['1']['precision'], 4),\n",
    "        'recall': round(report['1']['recall'], 4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"lstm_weekwise_results.csv\", index=False)\n",
    "print(\"\\n Training complete. Results saved to lstm_weekwise_results.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 Validate Saved Model File\n",
    "with h5py.File(model_path, 'r') as f:\n",
    "    print(\"Model file keys:\", list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 Reload Predictions\n",
    "results = []\n",
    "for week in [5, 10, 20, 38]:\n",
    "    print(f\"\\n=== Reloading Week {week} Predictions ===\")\n",
    "    y_pred_path = f\"predictions/y_pred_week{week}.npy\"\n",
    "    y_true_path = f\"predictions/y_true_week{week}.npy\"\n",
    "    if os.path.exists(y_pred_path) and os.path.exists(y_true_path):\n",
    "        y_pred = np.load(y_pred_path)\n",
    "        y_test = np.load(y_true_path)\n",
    "        y_pred_labels = (y_pred >= 0.5).astype(int)\n",
    "        report = classification_report(y_test, y_pred_labels, output_dict=True, zero_division=0)\n",
    "        results.append({\n",
    "            'week': week,\n",
    "            'accuracy': round(report['accuracy'], 4),\n",
    "            'precision': round(report['1']['precision'], 4),\n",
    "            'recall': round(report['1']['recall'], 4)\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Missing files for week {week}, skipping.\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"lstm_weekwise_results.csv\", index=False)\n",
    "print(\"\\n Reloaded results saved to lstm_weekwise_results.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e30e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 Baseline Models\n",
    "baseline_results = []\n",
    "for week in tqdm([5, 10, 20, 38], desc=\"Retrying Weeks\"):\n",
    "    print(f\"\\n--- Baseline Evaluation for Week {week} ---\")\n",
    "    X_week = X[:, :week, :].sum(axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_week, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(solver='liblinear', max_iter=1000, verbose=1),\n",
    "        \"SVM\": LinearSVC(max_iter=1000, verbose=1),\n",
    "        \"ANN\": MLPClassifier(\n",
    "            hidden_layer_sizes=(100,),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            max_iter=200,\n",
    "            early_stopping=True,\n",
    "            random_state=42,\n",
    "            verbose=True\n",
    "        )\n",
    "    }\n",
    "    for model_name in tqdm(models.keys(), desc=f\"Training Models for Week {week}\"):\n",
    "        model = models[model_name]\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        if hasattr(model, \"solver\"):\n",
    "            print(f\"Using solver for {model_name}: {model.solver}\")\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        runtime = round(time.time() - start, 2)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        acc = round(report[\"accuracy\"], 4)\n",
    "        prec = round(report[\"1\"][\"precision\"], 4)\n",
    "        rec = round(report[\"1\"][\"recall\"], 4)\n",
    "        print(f\"{model_name} @ Week {week} → Accuracy: {acc}, Precision: {prec}, Recall: {rec} (Time: {runtime}s)\")\n",
    "        baseline_results.append({\n",
    "            \"model\": model_name,\n",
    "            \"week\": week,\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"runtime_sec\": runtime\n",
    "        })\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "baseline_df.to_csv(\"baseline_model_results.csv\", mode='a', index=False, header=False)\n",
    "print(\"\\n Baseline results appended to baseline_model_results.csv\")\n",
    "baseline_df.drop_duplicates(subset=[\"model\", \"week\"], keep='last', inplace=True)\n",
    "baseline_df.to_csv(\"baseline_model_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346b437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
