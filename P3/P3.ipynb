{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P3 Reproduction Script\n",
    "\"\"\"\n",
    "Title: \"Student Success Prediction and the Trade-Off between Big Data and Data Minimization\"\n",
    "Authors: Hendrik Heuer, Andreas Breiter\n",
    "Source: Institute for Information Management Bremen (ifib) and Centre for Media, Communication and Information Research (ZeMKI), University of Bremen, Germany\n",
    "\n",
    "Purpose:\n",
    "This script reproduces the methodology and results of the above paper using the\n",
    "Open University Learning Analytics Dataset (OULAD). It executes the complete pipeline described in the paper:\n",
    "    - Data loading and preprocessing (removal of withdrawn students, exclusion of banked assessments, binary label encoding)\n",
    "    - Construction of daily activity vectors (count, binary, normalized) for a 245-day course window\n",
    "    - Demographic feature extraction with one-hot encoding of categorical attributes\n",
    "    - Creation of multiple feature set combinations\n",
    "    - Model training and 5-fold stratified cross-validation with:\n",
    "        * Decision Tree\n",
    "        * Random Forest\n",
    "        * Logistic Regression\n",
    "        * Support Vector Machine (RBF kernel)\n",
    "    - Reporting of Accuracy, Precision, Recall, and F1-score\n",
    "    - K-Means clustering (k=9) on binary activity vectors with visualization of mean interaction curves\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports and data loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import hstack\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "info = pd.read_csv(\"studentInfo.csv\")\n",
    "asmt = pd.read_csv(\"studentAssessment.csv\")\n",
    "vle = pd.read_csv(\"studentVle.csv\")\n",
    "asmt.head()\n",
    "info.head()\n",
    "assess = pd.read_csv(\"assessments.csv\")\n",
    "assess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data preprocessing\n",
    "filt = info[info[\"final_result\"] != \"Withdrawn\"].copy()\n",
    "banked = (asmt[asmt[\"is_banked\"] != 0]\n",
    "            .merge(assess[[\"id_assessment\", \"code_module\", \"code_presentation\"]],\n",
    "                   on=\"id_assessment\", how=\"left\")\n",
    "            [[\"code_module\", \"code_presentation\", \"id_student\"]]\n",
    "            .drop_duplicates())\n",
    "filt = (filt.merge(banked.assign(_drop=True),\n",
    "                   on=[\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "                   how=\"left\")\n",
    "            .query(\"_drop.isna()\")\n",
    "            .drop(columns=[\"_drop\"]))\n",
    "filt = filt.dropna(subset=[\"code_module\", \"code_presentation\", \"id_student\", \"final_result\"])\n",
    "LABEL_MAP = {\"Pass\": 1, \"Distinction\": 1, \"Fail\": 0}\n",
    "filt[\"label\"] = filt[\"final_result\"].map(LABEL_MAP).astype(int)\n",
    "df_filtered = filt[[\"code_module\", \"code_presentation\", \"id_student\", \"label\"]]\n",
    "df_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4814e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Activity vectors\n",
    "TIME_WINDOW = 245\n",
    "DAY_MIN, DAY_MAX = 0, 244\n",
    "vle = vle[(vle[\"date\"] >= DAY_MIN) & (vle[\"date\"] <= DAY_MAX)].copy()\n",
    "pivot = vle.pivot_table(index=[\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "                        columns=\"date\",\n",
    "                        values=\"sum_click\",\n",
    "                        aggfunc=\"sum\",\n",
    "                        fill_value=0)\n",
    "for d in range(TIME_WINDOW):\n",
    "    if d not in pivot.columns:\n",
    "        pivot[d] = 0\n",
    "pivot = pivot.sort_index(axis=1)\n",
    "clicks_matrix = pivot.values.astype(np.int32)\n",
    "inter_matrix  = (clicks_matrix > 0).astype(np.int8)\n",
    "max_clicks = clicks_matrix.max(axis=1, keepdims=True)\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    norm_matrix = np.where(max_clicks == 0, 0, clicks_matrix / max_clicks)\n",
    "df_vectors = pivot.reset_index()[[\"code_module\", \"code_presentation\", \"id_student\"]].copy()\n",
    "df_vectors[\"clicks_vector\"]       = list(clicks_matrix)\n",
    "df_vectors[\"interactions_vector\"] = list(inter_matrix)\n",
    "df_vectors[\"normalized_vector\"]   = list(norm_matrix)\n",
    "dataset = df_filtered.merge(df_vectors,\n",
    "                            on=[\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "                            how=\"inner\")\n",
    "print(f\"Shape: {dataset.shape}\")\n",
    "dataset.head()\n",
    "missing_any = dataset.isnull().any(axis=1).sum()\n",
    "missing_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Feature sets\n",
    "KEYS = [\"code_module\", \"code_presentation\", \"id_student\"]\n",
    "y      = dataset[\"label\"].values\n",
    "key_df = dataset[KEYS]\n",
    "print(\"Label vector shape:\", y.shape, \"| positive class share:\", y.mean().round(4))\n",
    "\n",
    "cols_cat = [\"age_band\", \"disability\", \"gender\", \"highest_education\", \"region\"]\n",
    "cols_num = [\"num_of_prev_attempts\", \"studied_credits\"]\n",
    "stu_raw  = info[KEYS + cols_cat + cols_num]\n",
    "X_info = (key_df\n",
    "          .merge(stu_raw, on=KEYS, how=\"left\")\n",
    "          .pipe(lambda df: pd.concat([\n",
    "                 pd.get_dummies(df[cols_cat]),\n",
    "                 df[cols_num].fillna(0)\n",
    "          ], axis=1))\n",
    "          .fillna(0)\n",
    "          .values.astype(float))\n",
    "print(\"Student-info feature matrix:\", X_info.shape)\n",
    "\n",
    "X_count = np.vstack(dataset[\"clicks_vector\"].values).astype(float)\n",
    "X_bin   = np.vstack(dataset[\"interactions_vector\"].values).astype(float)\n",
    "X_norm  = np.vstack(dataset[\"normalized_vector\"].values).astype(float)\n",
    "print(\"Activity matrices  |  count:\", X_count.shape,\n",
    "      \"| binary:\", X_bin.shape,\n",
    "      \"| normalized:\", X_norm.shape)\n",
    "\n",
    "feature_sets = {\n",
    "    \"activity_count\"  : X_count,\n",
    "    \"info+binary\"     : hstack([X_info, X_bin]),\n",
    "    \"info+normal\"     : hstack([X_info, X_norm]),\n",
    "    \"info+count\"      : hstack([X_info, X_count])\n",
    "}\n",
    "for k, v in feature_sets.items():\n",
    "    print(f\"{k:<15} → {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedaf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Models\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scorers = {\"acc\":  make_scorer(accuracy_score),\n",
    "           \"prec\": make_scorer(precision_score),\n",
    "           \"rec\":  make_scorer(recall_score),\n",
    "           \"f1\":   make_scorer(f1_score)}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "for name, X in feature_sets.items():\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scorers, n_jobs=-1)\n",
    "    print(f\"{name:<15}  \"\n",
    "          f\"Acc {scores['test_acc'].mean():.3f}  \"\n",
    "          f\"Prec {scores['test_prec'].mean():.3f}  \"\n",
    "          f\"Rec {scores['test_rec'].mean():.3f}  \"\n",
    "          f\"F1 {scores['test_f1'].mean():.3f}\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scorers = {\"acc\":  make_scorer(accuracy_score),\n",
    "           \"prec\": make_scorer(precision_score),\n",
    "           \"rec\":  make_scorer(recall_score),\n",
    "           \"f1\":   make_scorer(f1_score)}\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "for name, X in feature_sets.items():\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scorers, n_jobs=-1)\n",
    "    print(f\"{name:<15}  \"\n",
    "          f\"Acc {scores['test_acc'].mean():.3f}  \"\n",
    "          f\"Prec {scores['test_prec'].mean():.3f}  \"\n",
    "          f\"Rec {scores['test_rec'].mean():.3f}  \"\n",
    "          f\"F1 {scores['test_f1'].mean():.3f}\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scorers = {\"acc\":  make_scorer(accuracy_score),\n",
    "           \"prec\": make_scorer(precision_score),\n",
    "           \"rec\":  make_scorer(recall_score),\n",
    "           \"f1\":   make_scorer(f1_score)}\n",
    "clf = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", max_iter=1000, random_state=0)\n",
    "for name, X in feature_sets.items():\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scorers, n_jobs=-1)\n",
    "    print(f\"{name:<15}  \"\n",
    "          f\"Acc {scores['test_acc'].mean():.3f}  \"\n",
    "          f\"Prec {scores['test_prec'].mean():.3f}  \"\n",
    "          f\"Rec {scores['test_rec'].mean():.3f}  \"\n",
    "          f\"F1 {scores['test_f1'].mean():.3f}\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scorers = {\"acc\":  make_scorer(accuracy_score),\n",
    "           \"prec\": make_scorer(precision_score),\n",
    "           \"rec\":  make_scorer(recall_score),\n",
    "           \"f1\":   make_scorer(f1_score)}\n",
    "clf = SVC(kernel=\"rbf\", gamma=\"auto\", C=1.0, random_state=0)\n",
    "for name, X in feature_sets.items():\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scorers, n_jobs=-1)\n",
    "    print(f\"{name:<15}  \"\n",
    "          f\"Acc {scores['test_acc'].mean():.3f}  \"\n",
    "          f\"Prec {scores['test_prec'].mean():.3f}  \"\n",
    "          f\"Rec {scores['test_rec'].mean():.3f}  \"\n",
    "          f\"F1 {scores['test_f1'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Clustering\n",
    "days = np.arange(X_bin.shape[1])\n",
    "kmeans = KMeans(n_clusters=9, random_state=0, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_bin)\n",
    "inter_df = pd.DataFrame(X_bin, columns=days)\n",
    "inter_df[\"cluster\"] = cluster_labels\n",
    "cluster_curves = inter_df.groupby(\"cluster\").mean().sort_index()\n",
    "print(\"Cluster sizes:\", inter_df[\"cluster\"].value_counts().sort_index().tolist())\n",
    "cluster_curves.head()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.plot(days, cluster_curves.loc[i].values)\n",
    "    ax.set_title(f\"Cluster {i}  (n={inter_df.cluster.value_counts()[i]})\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(alpha=0.2)\n",
    "fig.suptitle(\"Mean binary activity curves per K-Means cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "order = cluster_curves.mean(axis=1).sort_values(ascending=False).index\n",
    "plt.figure(figsize=(12, 7))\n",
    "for i in order:\n",
    "    curve = cluster_curves.loc[i].rolling(window=7, center=True, min_periods=1).mean()\n",
    "    plt.plot(days, curve, label=f\"Cluster {i}\")\n",
    "plt.xlabel(\"Course day (0–244)\")\n",
    "plt.ylabel(\"7-day smoothed mean interaction\")\n",
    "plt.title(\"K-Means clusters (ordered, smoothed)\")\n",
    "plt.legend(ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
