{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ca67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 4 Reproduction Script\n",
    "\"\"\"\n",
    "Title: \"The Application of Gaussian Mixture Models for the Identification of At-Risk Learners in Massive Open Online Courses\"\n",
    "Authors: Raghad Alshabandar, Abir Jaafar Hussain, Robert Keight, Andy Laws, Thar Baker\n",
    "Source: Department of Computer Science, Liverpool John Moores University, UK\n",
    "\n",
    "Purpose:\n",
    "This script reproduces the methodology and results of the above paper using the \n",
    "Open University Learning Analytics Dataset (OULAD), focusing on the BBB-2013B \n",
    "presentation. It executes the complete pipeline described in the paper:\n",
    "    - Data loading and preprocessing\n",
    "    - Interval-based feature engineering from Virtual Learning Environment (VLE) logs\n",
    "    - Label creation for on-time vs. late/non-submission\n",
    "    - Model training and evaluation per interval using:\n",
    "        * Eigenvalue Decomposition Discriminant Analysis (EDDA)\n",
    "        * Logistic Regression\n",
    "        * k-Nearest Neighbors (kNN)\n",
    "    - Performance aggregation across multiple randomized splits\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f696c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f618c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSE = \"BBB\"\n",
    "PRES   = \"2013B\"\n",
    "DATA_DIR = Path(\".\")\n",
    "CSV_OUT = Path(\"all_metrics.csv\")\n",
    "RIDGE      = 1e-3\n",
    "N_REPEATS  = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Loading and Manipulation \n",
    "read = lambda f: pd.read_csv(DATA_DIR / f)\n",
    "\n",
    "student_info       = read(\"studentInfo.csv\")\n",
    "student_vle        = read(\"studentVle.csv\")\n",
    "assessments        = read(\"assessments.csv\")\n",
    "student_assessment = read(\"studentAssessment.csv\")\n",
    "vle                = read(\"vle.csv\")\n",
    "\n",
    "student_assessment = student_assessment.merge(\n",
    "    assessments[[\"id_assessment\",\"code_module\",\"code_presentation\"]],\n",
    "    on=\"id_assessment\", how=\"left\"\n",
    ")\n",
    "\n",
    "student_vle = student_vle.merge(vle[[\"id_site\",\"activity_type\"]], on=\"id_site\", how=\"left\")\n",
    "\n",
    "mask = (student_info.code_module == COURSE) & (student_info.code_presentation == PRES)\n",
    "filtered_info   = student_info.loc[mask]\n",
    "\n",
    "mask = (student_vle.code_module == COURSE) & (student_vle.code_presentation == PRES)\n",
    "filtered_vle    = student_vle.loc[mask]\n",
    "\n",
    "mask = (assessments.code_module == COURSE) & (assessments.code_presentation == PRES)\n",
    "filtered_assessments = assessments.loc[mask]\n",
    "\n",
    "mask = (student_assessment.code_module == COURSE) & (student_assessment.code_presentation == PRES)\n",
    "filtered_student_assess = student_assessment.loc[mask]\n",
    "\n",
    "print(f\"✓ Loaded course {COURSE}-{PRES}\")\n",
    "print(\"  studentInfo       :\", filtered_info.shape)\n",
    "print(\"  studentVle        :\", filtered_vle.shape)\n",
    "print(\"  assessments       :\", filtered_assessments.shape)\n",
    "print(\"  studentAssessment :\", filtered_student_assess.shape)\n",
    "\n",
    "bbb_students = (\n",
    "    filtered_info[[\"id_student\",\"code_module\",\"code_presentation\"]]\n",
    "      .drop_duplicates()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - defining time intervals\n",
    "deadline_dates = (\n",
    "    filtered_assessments\n",
    "      .query(\"assessment_type in ['TMA','CMA'] and weight > 0\")\n",
    "      .sort_values(\"date\")\n",
    "      .drop_duplicates(subset=\"date\")\n",
    "      [\"date\"]\n",
    "      .head(6)\n",
    "      .tolist()\n",
    ")\n",
    "if len(deadline_dates) < 6:\n",
    "    raise ValueError(\"Fewer than six graded deadlines found for this course!\")\n",
    "print(\"✓ Deadlines (days since course start):\", deadline_dates)\n",
    "\n",
    "assignments_by_interval = (\n",
    "    filtered_assessments\n",
    "      .query(\"date in @deadline_dates\")\n",
    "      .sort_values(\"date\")\n",
    "      .groupby(\"date\")\n",
    "      .head(1)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "assignments_by_interval[\"interval\"] = np.arange(1, 7)\n",
    "\n",
    "edges = [-np.inf] + deadline_dates\n",
    "def day_to_interval(day):\n",
    "    for i in range(1, len(edges)):\n",
    "        if day <= edges[i]:\n",
    "            return i\n",
    "    return 6\n",
    "\n",
    "filtered_vle[\"interval\"] = filtered_vle[\"date\"].apply(day_to_interval)\n",
    "\n",
    "print(\"\\nClicks per interval\")\n",
    "print(filtered_vle[\"interval\"].value_counts().sort_index())\n",
    "print(\"\\nassignments_by_interval:\")\n",
    "display(assignments_by_interval[[\"interval\",\"id_assessment\",\"date\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Feature Engineering\n",
    "canonical = [\n",
    "    \"homepage\",\"resource\",\"url\",\"forumng\",\"oucontent\",\"subpage\",\n",
    "    \"quiz\",\"oucollaborate\",\"externaltool\",\"ouwiki\",\"dataplus\",\n",
    "    \"ouelluminate\",\"oublog\",\"checkmark\",\"scheduler\",\"sharedsubpage\",\n",
    "    \"page\",\"repeatactivity\",\"htmlactivity\",\"feedback\",\"glossary\",\n",
    "    \"dualpane\"\n",
    "]\n",
    "\n",
    "filtered_vle = filtered_vle.copy()\n",
    "filtered_vle[\"interval\"] = filtered_vle[\"date\"].apply(day_to_interval)\n",
    "\n",
    "session_counts = (\n",
    "    filtered_vle\n",
    "      .groupby([\"id_student\", \"interval\", \"activity_type\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"num_sessions\")\n",
    ")\n",
    "click_counts = (\n",
    "    filtered_vle\n",
    "      .groupby([\"id_student\", \"interval\", \"activity_type\"])[\"sum_click\"]\n",
    "      .sum()\n",
    "      .reset_index(name=\"total_clicks\")\n",
    ")\n",
    "\n",
    "feat_long = session_counts.merge(click_counts, on=[\"id_student\", \"interval\", \"activity_type\"])\n",
    "sessions_w = (\n",
    "    feat_long.pivot_table(index=[\"id_student\", \"interval\"],\n",
    "                          columns=\"activity_type\",\n",
    "                          values=\"num_sessions\",\n",
    "                          fill_value=0)\n",
    ")\n",
    "clicks_w = (\n",
    "    feat_long.pivot_table(index=[\"id_student\", \"interval\"],\n",
    "                          columns=\"activity_type\",\n",
    "                          values=\"total_clicks\",\n",
    "                          fill_value=0)\n",
    ")\n",
    "\n",
    "sessions_w.columns = [f\"session_{c}\" for c in sessions_w.columns]\n",
    "clicks_w.columns   = [f\"clicks_{c}\"  for c in clicks_w.columns]\n",
    "\n",
    "full_idx = pd.MultiIndex.from_product(\n",
    "    [bbb_students[\"id_student\"].unique(), range(1, 7)],\n",
    "    names=[\"id_student\", \"interval\"]\n",
    ").to_frame(index=False)\n",
    "\n",
    "features = (\n",
    "    full_idx\n",
    "      .merge(sessions_w.reset_index(), how=\"left\")\n",
    "      .merge(clicks_w.reset_index(),  how=\"left\")\n",
    "      .fillna(0)\n",
    ")\n",
    "\n",
    "all_types = vle[\"activity_type\"].unique()\n",
    "for t in all_types:\n",
    "    for prefix in (\"session_\", \"clicks_\"):\n",
    "        col = f\"{prefix}{t}\"\n",
    "        if col not in features.columns:\n",
    "            features[col] = 0\n",
    "for t in canonical:\n",
    "    for prefix in (\"session_\", \"clicks_\"):\n",
    "        col = f\"{prefix}{t}\"\n",
    "        if col not in features.columns:\n",
    "            features[col] = 0\n",
    "\n",
    "keep_cols = (\n",
    "    [\"id_student\", \"interval\"] +\n",
    "    [f\"session_{t}\" for t in canonical] +\n",
    "    [f\"clicks_{t}\"  for t in canonical]\n",
    ")\n",
    "final_features = features[keep_cols].copy()\n",
    "print(\" final_features shape:\", final_features.shape)\n",
    "print(\"  (should be 6 × #students rows, 46 columns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Label generation\n",
    "\n",
    "tma_pool = (\n",
    "    filtered_assessments\n",
    "      .query(\"assessment_type == 'TMA' and weight > 0\")\n",
    "      .sort_values(\"date\")\n",
    "      .head(6)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "tma_pool[\"interval\"] = range(1, 7)\n",
    "print(\"✓ Deadlines (days since course start):\", tma_pool[\"date\"].tolist())\n",
    "\n",
    "sa_clean = (\n",
    "    filtered_student_assess\n",
    "      .loc[filtered_student_assess[\"is_banked\"] == 0]\n",
    "      .dropna(subset=[\"date_submitted\"])\n",
    ")\n",
    "sa_merged = (\n",
    "    sa_clean\n",
    "      .merge(tma_pool[[\"id_assessment\", \"interval\", \"date\"]],\n",
    "             on=\"id_assessment\", how=\"inner\", validate=\"many_to_one\")\n",
    ")\n",
    "first_sub = (\n",
    "    sa_merged\n",
    "      .groupby([\"id_student\", \"interval\"], as_index=False)[\"date_submitted\"]\n",
    "      .min()\n",
    ")\n",
    "first_sub = first_sub.merge(tma_pool[[\"interval\", \"date\"]], on=\"interval\")\n",
    "first_sub[\"on_time\"] = first_sub[\"date_submitted\"] <= first_sub[\"date\"]\n",
    "\n",
    "label_grid = (\n",
    "    pd.MultiIndex.from_product(\n",
    "        [bbb_students[\"id_student\"].unique(), range(1, 7)],\n",
    "        names=[\"id_student\", \"interval\"]\n",
    "    ).to_frame(index=False)\n",
    "      .merge(first_sub[[\"id_student\", \"interval\", \"on_time\"]],\n",
    "             on=[\"id_student\", \"interval\"], how=\"left\")\n",
    "      .fillna({\"on_time\": False})\n",
    ")\n",
    "label_grid[\"Y\"] = 1 - label_grid[\"on_time\"].astype(int)\n",
    "labels = label_grid[[\"id_student\", \"interval\", \"Y\"]]\n",
    "\n",
    "final_features = final_features.merge(labels, on=[\"id_student\", \"interval\"], how=\"left\")\n",
    "print(\"\\nDistribution of Y per interval (fractions):\")\n",
    "print((final_features.groupby(\"interval\")[\"Y\"]\n",
    "       .value_counts(normalize=True)\n",
    "       .unstack()\n",
    "       .round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Functions\n",
    "def make_slice(full_df, t):\n",
    "    cur = full_df[full_df.interval == t].set_index(\"id_student\")\n",
    "    if t == 1:\n",
    "        return cur.reset_index()\n",
    "    prev = full_df[full_df.interval == t-1].set_index(\"id_student\").add_suffix(\"_prev\")\n",
    "    return cur.join(prev, how=\"left\").fillna(0).reset_index()\n",
    "\n",
    "def log_lik(clf, X, y):\n",
    "    lp = clf.predict_log_proba(X)\n",
    "    return lp[np.arange(len(y)), y].sum()\n",
    "\n",
    "def bic(loglik, free_params, n):\n",
    "    return -2*loglik + free_params*np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5579ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Modelling\n",
    "all_rows = []\n",
    "for t in range(1, 7):\n",
    "    df_t   = make_slice(final_features, t)\n",
    "    X_full = df_t.filter(regex=\"^(session_|clicks_)\").values\n",
    "    y_full = df_t[\"Y\"].values\n",
    "\n",
    "    active = X_full.sum(axis=1) > 0\n",
    "    X_full, y_full = X_full[active], y_full[active]\n",
    "\n",
    "    if len(np.unique(y_full)) < 2:\n",
    "        print(f\"⚠︎  t={t}: only one class present → skipped\")\n",
    "        continue\n",
    "\n",
    "    for run in range(N_REPEATS):\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "            X_full, y_full, test_size=.40, stratify=y_full,\n",
    "            random_state=GLOBAL_SEED + run\n",
    "        )\n",
    "\n",
    "        eee = Pipeline([\n",
    "            (\"sc\",  StandardScaler()),\n",
    "            (\"lda\", LinearDiscriminantAnalysis(solver=\"lsqr\", shrinkage=RIDGE))\n",
    "        ]).fit(X_tr, y_tr)\n",
    "\n",
    "        vvv = Pipeline([\n",
    "            (\"sc\",  StandardScaler()),\n",
    "            (\"qda\", QuadraticDiscriminantAnalysis(reg_param=RIDGE, store_covariance=True))\n",
    "        ]).fit(X_tr, y_tr)\n",
    "\n",
    "        n, p, k = X_tr.shape[0], X_tr.shape[1], 2\n",
    "        bic_eee = bic(log_lik(eee, X_tr, y_tr), p*(p+1)/2 + k*p, n)\n",
    "        bic_vvv = bic(log_lik(vvv, X_tr, y_tr), k*(p + p*(p+1)/2), n)\n",
    "        edda_best = eee if bic_eee < bic_vvv else vvv\n",
    "\n",
    "        logreg = Pipeline([\n",
    "            (\"sc\",  StandardScaler()),\n",
    "            (\"lr\",  LogisticRegression(C=10, max_iter=500, class_weight=\"balanced\"))\n",
    "        ]).fit(X_tr, y_tr)\n",
    "\n",
    "        knn = Pipeline([\n",
    "            (\"sc\",  StandardScaler()),\n",
    "            (\"knn\", KNeighborsClassifier(n_neighbors=10))\n",
    "        ]).fit(X_tr, y_tr)\n",
    "\n",
    "        for name, mdl in {\"EDDA\": edda_best, \"LogReg\": logreg, \"kNN\": knn}.items():\n",
    "            prob = mdl.predict_proba(X_te)[:, 1]\n",
    "            pred = mdl.predict(X_te)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(y_te, pred).ravel()\n",
    "            sens = tp / (tp + fn) if tp + fn else 0\n",
    "            spec = tn / (tn + fp) if tn + fp else 0\n",
    "\n",
    "            all_rows.append({\n",
    "                \"interval\":    t,\n",
    "                \"model\":       name,\n",
    "                \"accuracy\":    accuracy_score(y_te, pred),\n",
    "                \"f1\":          f1_score(y_te, pred, zero_division=0),\n",
    "                \"sensitivity\": sens,\n",
    "                \"specificity\": spec,\n",
    "                \"auc\":         roc_auc_score(y_te, prob)\n",
    "            })\n",
    "\n",
    "    print(f\"finished t={t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb88a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8: metric saves\n",
    "metrics_df = (pd.DataFrame(all_rows)\n",
    "                .groupby([\"interval\", \"model\"])\n",
    "                .median()\n",
    "                .reset_index()\n",
    "                .sort_values([\"interval\", \"model\"]))\n",
    "metrics_df.to_csv(CSV_OUT, index=False)\n",
    "display(metrics_df.round(3))\n",
    "print(f\"metrics (median over {N_REPEATS} splits) → {CSV_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6052e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paper4-env",
   "language": "python",
   "name": "paper4-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
