{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 5 Reproduction Script\n",
    "\"\"\"\n",
    "Title: \"Predicting at-risk university students in a virtual learning environment via a machine learning algorithm\"\n",
    "Authors: Kwok Tai Chui, Dennis Chun Lok Fung, Miltiadis D. Lytras, Tin Miu Lam (Computers in Human Behavior, 2020)\n",
    "\n",
    "\n",
    "\n",
    "Purpose:\n",
    "End-to-end entry-point script for RTV-SVM reproduction with exact-match settings:\n",
    "    - Data loading and filtering (exclude Withdrawn; labels from final_score)\n",
    "    - Feature engineering: 10 numeric + k-1 one-hot for categorical = 52 predictors\n",
    "    - Preprocessing: mean impute + z-scale (numeric), k-1 OneHotEncoder (categorical)\n",
    "    - Five-fold Stratified CV per module\n",
    "    - RTV-SVM reductions: tier-1 (log-pdf) and tier-2 (projection) scenarios S1–S4\n",
    "    - Metrics: R_tv, M_r, T1, T2, Se, Sp, OA\n",
    "    - Outputs: printed aggregates for Tables 3, 4, and 5\n",
    "\n",
    "Notes:\n",
    "    - RNG seeds are set at the top of the script.\n",
    "    - No logic added or removed from the original implementation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab79817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Seeds and imports\n",
    "import os, random, time, warnings, numpy as np, pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f32992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Step 1: Load OULAD CSVs\n",
    "    student_info        = pd.read_csv(\"studentInfo.csv\")\n",
    "    student_vle         = pd.read_csv(\"studentVle.csv\")\n",
    "    student_assessment  = pd.read_csv(\"studentAssessment.csv\")\n",
    "    assessments         = pd.read_csv(\"assessments.csv\")\n",
    "    student_registration= pd.read_csv(\"studentRegistration.csv\")\n",
    "\n",
    "    # Step 2: Labels\n",
    "    student_info = student_info[student_info.final_result != \"Withdrawn\"].copy()\n",
    "    merged = (student_assessment\n",
    "              .merge(assessments[['id_assessment','weight',\n",
    "                                  'code_module','code_presentation']],\n",
    "                     on='id_assessment', how='left'))\n",
    "    merged['weighted'] = merged['score'] * merged['weight'] / 100.0\n",
    "    final_scores = (merged\n",
    "                    .groupby(['id_student','code_module','code_presentation'],\n",
    "                             as_index=False)['weighted']\n",
    "                    .sum()\n",
    "                    .rename(columns={'weighted':'final_score'}))\n",
    "    student_info = (student_info\n",
    "                    .merge(final_scores, on=['id_student','code_module',\n",
    "                                             'code_presentation'], how='left'))\n",
    "    student_info = student_info[student_info.final_score.notna()]\n",
    "    student_info['label_binary'] = (student_info.final_score < 40).astype(int)\n",
    "    def _tri(s):\n",
    "        if s >= 55:   return 0\n",
    "        if s >= 40:   return 1\n",
    "        return 2\n",
    "    student_info['label_multi'] = student_info.final_score.apply(_tri)\n",
    "\n",
    "    # Step 3: Activity and assessment features\n",
    "    vle_feat = (\n",
    "        student_vle\n",
    "        .groupby([\"id_student\", \"code_module\", \"code_presentation\"])\n",
    "        .agg(total_clicks   = (\"sum_click\", \"sum\"),\n",
    "             days_active    = (\"date\",      \"nunique\"),\n",
    "             resources_used = (\"id_site\",   \"nunique\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    sa_feat = (\n",
    "        student_assessment\n",
    "        .merge(assessments[[\"id_assessment\", \"weight\",\n",
    "                            \"code_module\", \"code_presentation\"]],\n",
    "               on=\"id_assessment\", how=\"left\")\n",
    "        .groupby([\"id_student\", \"code_module\", \"code_presentation\"])\n",
    "        .agg(n_assess   = (\"id_assessment\", \"size\"),\n",
    "             mean_score = (\"score\", \"mean\"),\n",
    "             std_score  = (\"score\", \"std\"),\n",
    "             miss_asmt  = (\"score\", lambda s: s.isna().sum()))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Step 4: Master table\n",
    "    master = (\n",
    "        student_info\n",
    "        .merge(student_registration[[\"id_student\",\"code_module\",\n",
    "                                     \"code_presentation\",\"date_registration\"]],\n",
    "               on=[\"id_student\",\"code_module\",\"code_presentation\"], how=\"left\")\n",
    "        .merge(vle_feat, on=[\"id_student\",\"code_module\",\"code_presentation\"],\n",
    "               how=\"left\")\n",
    "        .merge(sa_feat, on=[\"id_student\",\"code_module\",\"code_presentation\"],\n",
    "               how=\"left\")\n",
    "    )\n",
    "    behav_cols = [\"total_clicks\",\"days_active\",\"resources_used\",\n",
    "                  \"n_assess\",\"mean_score\",\"std_score\",\"miss_asmt\"]\n",
    "    master[behav_cols] = master[behav_cols].fillna(0)\n",
    "    bins   = [0,30,60,90,120,np.inf]\n",
    "    labels = [\"30\",\"60\",\"90\",\"120\",\"150+\"]\n",
    "    master[\"studied_credits_cat\"] = pd.cut(master.studied_credits,\n",
    "                                           bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # Step 5: Explicit category sets\n",
    "    cat_levels = {\n",
    "        \"code_module\": [\"AAA\",\"BBB\",\"CCC\",\"DDD\",\"EEE\",\"FFF\",\"GGG\"],\n",
    "        \"code_presentation\": [\"2013B\",\"2013J\",\"2014B\",\"2014J\"],\n",
    "        \"gender\": [\"F\",\"M\"],\n",
    "        \"region\": [\n",
    "            \"East Anglian Region\",\"East Midlands Region\",\"Ireland\",\"London Region\",\n",
    "            \"North Region\",\"North Western Region\",\"Northern Ireland\",\"Scotland\",\n",
    "            \"South East Region\",\"South Region\",\"South West Region\",\"Wales\",\n",
    "            \"West Midlands Region\"\n",
    "        ],\n",
    "        \"highest_education\": [\n",
    "            \"No Formal quals\",\"Lower Than A Level\",\"A Level or Equivalent\",\n",
    "            \"HE Qualification\",\"Post Graduate Qualification\"\n",
    "        ],\n",
    "        \"imd_band\": [\n",
    "            \"0-10%\",\"10-20%\",\"20-30%\",\"30-40%\",\"40-50%\",\n",
    "            \"50-60%\",\"60-70%\",\"70-80%\",\"80-90%\",\"90-100%\"\n",
    "        ],\n",
    "        \"age_band\": [\"0-35\",\"35-55\",\"55<=\"],\n",
    "        \"disability\": [\"N\",\"Y\"],\n",
    "        \"studied_credits_cat\": labels,\n",
    "    }\n",
    "    for col, cats in cat_levels.items():\n",
    "        master[col] = pd.Categorical(master[col], categories=cats)\n",
    "\n",
    "    # Step 6: Predictor lists\n",
    "    numeric_cols = [\n",
    "        \"studied_credits\",\"num_of_prev_attempts\",\"date_registration\",\n",
    "        *behav_cols,\n",
    "    ]\n",
    "    categorical_cols = list(cat_levels.keys())\n",
    "\n",
    "    # Step 7: Preprocessing\n",
    "    preproc = ColumnTransformer([\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"sc\",  StandardScaler())\n",
    "        ]), numeric_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(categories=[cat_levels[c] for c in categorical_cols],\n",
    "                                   drop=\"first\", sparse=True))\n",
    "        ]), categorical_cols)\n",
    "    ])\n",
    "    X_mat = preproc.fit_transform(master)\n",
    "    y_bin = master[\"label_binary\"].values\n",
    "    y_tri = master[\"label_multi\"].values\n",
    "\n",
    "    # Step 8: Sanity check\n",
    "    ohe = preproc.named_transformers_[\"cat\"][\"ohe\"]\n",
    "    feat_names = list(numeric_cols) + list(ohe.get_feature_names(categorical_cols))\n",
    "    assert X_mat.shape[1] == 52, f\"{X_mat.shape[1]} ≠ 52 predictors\"\n",
    "    X_df = pd.DataFrame(X_mat.toarray() if sparse.issparse(X_mat) else X_mat,\n",
    "                        columns=feat_names, index=master.index)\n",
    "    X = X_df.values\n",
    "    print(\"✔ predictor count:\", X.shape[1])\n",
    "\n",
    "    # Step 9: RTV-SVM helpers\n",
    "    R_TH = 0.35\n",
    "    def tier1_pdf_mask(X, y):\n",
    "        keep = np.zeros_like(y, dtype=bool)\n",
    "        for cls in (0, 1):\n",
    "            idx = np.where(y == cls)[0]\n",
    "            Xc  = X[idx]\n",
    "            mu  = Xc.mean(0)\n",
    "            Σ   = np.diag(Xc.var(0) + 1e-6)\n",
    "            logp = multivariate_normal.logpdf(Xc, mu, Σ)\n",
    "            r    = np.exp(logp.min() - logp.max())\n",
    "            Nt   = max(int(np.floor(len(Xc) * r / R_TH)), 1)\n",
    "            keep[idx[np.argsort(logp)[:Nt]]] = True\n",
    "        return keep\n",
    "    def tier2_proj_mask(X, y, init):\n",
    "        keep = init.copy()\n",
    "        while True:\n",
    "            changed = False\n",
    "            I = np.where(keep)[0]\n",
    "            Xk, yk = X[I], y[I]\n",
    "            mu0, mu1 = Xk[yk==0].mean(0), Xk[yk==1].mean(0)\n",
    "            v = mu1 - mu0\n",
    "            v_len = np.linalg.norm(v) + 1e-12\n",
    "            for cls, mu_s in ((0, mu0), (1, mu1)):\n",
    "                Ic = I[yk == cls]\n",
    "                if Ic.size <= 1:\n",
    "                    continue\n",
    "                d    = X[Ic] - mu_s\n",
    "                dlen = np.linalg.norm(d, axis=1) + 1e-12\n",
    "                cos  = (d @ v) / (dlen * v_len)\n",
    "                proj = dlen * cos\n",
    "                forward = cos > 0\n",
    "                if not forward.any():\n",
    "                    continue\n",
    "                kill = Ic[forward][proj[forward].argmin()]\n",
    "                keep[kill] = False\n",
    "                changed = True\n",
    "            if not changed:\n",
    "                break\n",
    "        return keep\n",
    "    def _svc():\n",
    "        return SVC(kernel=\"rbf\", C=10.0, gamma=\"auto\")\n",
    "    def svm_metrics(Xtr, ytr, Xte, yte):\n",
    "        clf = _svc(); t0=time.time(); clf.fit(Xtr, ytr);  T1=time.time()-t0\n",
    "        t0=time.time(); pred = clf.predict(Xte);          T2=time.time()-t0\n",
    "        tn, fp, fn, tp = confusion_matrix(yte, pred).ravel()\n",
    "        Se, Sp = tp/(tp+fn+1e-12), tn/(tn+fp+1e-12)\n",
    "        OA      = accuracy_score(yte, pred)\n",
    "        return dict(T1=T1, T2=T2, Se=Se, Sp=Sp, OA=OA), clf\n",
    "    def run_scenarios(Xtr, ytr, Xte, yte):\n",
    "        base, ref = svm_metrics(Xtr, ytr, Xte, yte)\n",
    "        sv_mask = np.zeros_like(ytr, bool); sv_mask[ref.support_] = True\n",
    "        out = {\"S1\": dict(R_tv=0.0, M_r=\"N/A\", **base)}\n",
    "        k1 = tier1_pdf_mask(Xtr, ytr) | sv_mask\n",
    "        met,_ = svm_metrics(Xtr[k1], ytr[k1], Xte, yte)\n",
    "        out[\"S2\"] = dict(R_tv=100*(1-k1.mean()), M_r=\"No\", **met)\n",
    "        k2 = tier2_proj_mask(Xtr, ytr, np.ones_like(ytr, bool)) | sv_mask\n",
    "        met,_ = svm_metrics(Xtr[k2], ytr[k2], Xte, yte)\n",
    "        out[\"S3\"] = dict(R_tv=100*(1-k2.mean()), M_r=\"No\", **met)\n",
    "        k12 = tier2_proj_mask(Xtr, ytr, k1) | sv_mask\n",
    "        met,_ = svm_metrics(Xtr[k12], ytr[k12], Xte, yte)\n",
    "        out[\"S4\"] = dict(R_tv=100*(1-k12.mean()), M_r=\"No\", **met)\n",
    "        return out\n",
    "\n",
    "        # Step 10: Re-create Tables 3–5\n",
    "    wanted = [\"AAA\",\"BBB\",\"CCC\",\"DDD\",\"EEE\",\"FFF\",\"GGG\"]\n",
    "    order  = [\"S1\",\"S2\",\"S3\",\"S4\"]\n",
    "    cv     = StratifiedKFold(5, shuffle=True, random_state=0)\n",
    "    rows3, rows5 = [], []\n",
    "\n",
    "    for mod in wanted:\n",
    "        m = master.code_module == mod\n",
    "        Xc = X[m]\n",
    "        y_bin_c  = y_bin[m]\n",
    "        y_both_c = np.where(y_tri[m] == 0, 0, 1)\n",
    "\n",
    "        if np.unique(y_bin_c).size < 2:\n",
    "            continue\n",
    "\n",
    "        for tr, te in cv.split(Xc, y_bin_c):\n",
    "            for scen, met in run_scenarios(Xc[tr], y_bin_c[tr], Xc[te], y_bin_c[te]).items():\n",
    "                rows3.append(dict(module=mod, scenario=scen, **met))\n",
    "\n",
    "        if np.unique(y_both_c).size < 2:\n",
    "            continue\n",
    "\n",
    "        for tr, te in cv.split(Xc, y_both_c):\n",
    "            for scen, met in run_scenarios(Xc[tr], y_both_c[tr], Xc[te], y_both_c[te]).items():\n",
    "                rows5.append(dict(module=mod, scenario=scen, **met))\n",
    "\n",
    "    # Step 11: Extra counts (single print after loop)\n",
    "    cnt = (student_info.groupby([\"code_module\", \"final_result\"]).size().unstack(fill_value=0))\n",
    "    print(cnt.loc[\"GGG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7441b790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33821e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f6df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d7d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8072c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
